2023年08月03日 meetingnotes:

结论，作业：

---

1、JAMIE 写个小文档数据导出来，项目+人的URL

2、怎么筛选出来 厉害的人/有趣的人





会议用文档：

## 背景信息：GPT和Diffusion模型时间线

2020之前- 2017年6月，Google发布Transformer论文。- 2017年6月，7月，OpenAI发布人类喜好的强化学习算法、PPO算法，都是ChatGPT用到的算法。- 2018年6月，OpenAI发布GPT-1.- 2018年11月，Google发布BERT，此后NLP领域主要基于这个框架研究下游任务。- 2019年2月，OpenAI发布GPT-2，OpenAI获得了自信，此后专注于GPT.

2020年

\- 年初，Covid-19爆发。

\- 1月，OpenAI发布语言模型的Scaling Law（概念：模型能力跟参数规模、数据规模强相关），OpenAI获得了在数据和参数规模上Scaling-up的信心。

\- 5月，GPT-3论文发布。

\- 6月，**GPT-3 API发布**。

\- 9月，ChatGPT的关键原型算法相关论文发布。

\- 12月，欧洲机构发布用于GPT-3复现的开源数据集。



2021年

\- 7月，OpenAI发布Copilot原型算法。

\- 8月，Codex API发布。

\- 11月，**GPT-3 API Public Release，不对中国开放**。



2022年

\- 1月，GPT-3.5 API (text-davinci-002)发布，该模型经过Github代码的训练加持，推理能力显著提升（该假设的因果关系待学术界论证），经过Alignment技术的加持，Follow人类指令的能力显著提升，输出结果有用性和无害性显著提升。

\- 3月，GPT-3.5论文发布，公开Alignment算法。

\- 5月，OpenAI Codex已经被70个应用使用，包括微软收购的Github的Copilot.

\- 8月，Stability AI开源StableDiffusion，文生图的算法的效果可用、速度可行、代码开源同时发生，引爆图片生成。一时间，在中国，AIGC似乎就是图片生成的代名词。

\- 9月，Sequoia Capital发布Generative AI: A Creative New World博客。

\- 中国研究人员和开发者，没有OpenAI的API权限。但图片生成却人人都可以尝试，于是互联网似乎只注意到了图片生成，对GPT大语言模型的关注度进一步下降。

\- 经过接近一年的API接入和UI探索、近一年的思维链（Chain of Thought）等Prompt Engineering技术试错、模型加速等技术（如Flash Attention、Fixed-Point）带来的成本和延迟下降，GPT-3.5的模型潜力得到开发（变得Better、Faster and Cheaper）, Copy.ai, Jasper等文本生成类公司的产品逐渐成熟。

\- 11月，OpenAI发布GPT3.5 API的新模型(text-davinci-003).

\- **12月1日，ChatGPT发布**。Musk等名流开始谈论ChatGPT，引爆英文互联网。

\- 12月初，中国互联网的自媒体逐渐开始讨论ChatGPT，主要以翻译twitter的方式。知乎上有学者开始反思。一周后，关注指数下降，两个月来只剩下AI自媒体把ChatGPT作为自己的主要关注内容。



2023年

\- 1月，微软宣布投资OpenAI数十亿美元，并将GPT加入全家桶



**2023年 3月15日**，ChatGPT4.0版本正式发布，chatgpt4发布 再度掀起热议。







## 碎片思考

### 关键词收集数据集

**按业界讨论分**

LLM 已经导出来1K

其他要导的关键词：

GLM---done

LM---done

LLaMA

Diffusion 

GPT



**【TODO：每个关键词star排名前1000，顺便把相关联的前1000的人URL导出来】**



### 分析角度

**相关的REPO**

项目分时间段，增长速度，增长量，分析

牛人筛选角度（新项目爆发增长人物，长时间影响力较强项目）

清洗，去重，补全基础数据，人物

人物有趣=star/followers



**两个话题**

最厉害/最牛的开发者

最有趣的开发者



（阳老师寄语时的参考信息

​	时间 什么时间段活跃的

​	空间 是不是在顶尖的公司任职，在哪个国家

​	变量 是不是创造了顶尖的大模型，是不是被引用的特别多，

​	其他 在推特上是不是活跃，其他开发者对他的认可程度，学术影响力）



**动态榜单**    

- **最牛开发者/团队**  筛选标准   

**=高星x35%+高forkx35%+个人followerx30%**   如果有多个项目 额外加分



整体榜单 （将所有关键词的放在一起算）

子榜单 LLM/GLM/LLaMA/LM

子榜单 GPT

子榜单 Difussion



**完善总榜和子榜的人物数据，进一步分析和定位相关的人**

人物详情数据----大学，公司，研究方向，研究经历

结合人物详情，repo的详情数据，更新进去



- **最不为人知的有趣开发者**

**= 项目高星数量/twiiter+github follower**



总榜单

大模型整体榜单

子榜单 LLM/GLM/LLaMA/LM

子榜单 GPT

子榜单 Diffusion



- **star/fork 比值计算**



- **闪电新星**

最快时间内破1万的项目，破1万的具体时间点，分不同的子榜单或不分





以上内容的缺陷，

有价值的信息是 反常识的，大部分人不知道的，不确定以上内容是否能筛出来不有价值的信息，但是可以尝试一波。可能的一些反常识的角度，不同模态的周期，不同模态的整体关注量，有没有跨越不同模态都很厉害的开发者等等。

还缺少了对具体内容的分析，比如在repo里高频被提到的一些词或者内容等等。这个可以数据集确定了，再具体分析。

未来可根据人物的更多具体参数，给人物打分，比如年龄，学校，地理位置，公司，社交网络影响力等等。或者联系作者访谈。



其他 github的项目详细信息参考

https://ossinsight.io/analyze/geekan/MetaGPT#overview

http://www.gharchive.org/

